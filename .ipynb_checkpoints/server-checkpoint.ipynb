{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78193045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import json\n",
    "import base64\n",
    "\n",
    "import io\n",
    "import json\n",
    "from flask import Flask, jsonify, request\n",
    "from PIL import Image\n",
    "import csv\n",
    "from model import U2NET\n",
    "from torch.autograd import Variable\n",
    "\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ccd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"image and portrait composite\")\n",
    "# parser.add_argument('-p',default='./test_data/test_portrait_images/your_portrait_im', help='input image folder path')\n",
    "parser.add_argument('-o',default='/home/ubuntu/workspace/kobaco/sketchy/U-2-Net/test_data/test_portrait_images/api_results', help='output path')\n",
    "parser.add_argument('-m1',default='/home/ubuntu/workspace/kobaco/sketchy/U-2-Net/saved_models/best/train_APDrawingGAN/u2net_bce_itr_50000_train_0.806755_tar_0.059212.pth', help='model path')\n",
    "parser.add_argument('-m2',default='/home/ubuntu/workspace/kobaco/sketchy/U-2-Net/saved_models/best/train_custom_nobg/custom_nobg_bce_itr_60000_train_0.369949_tar_0.032807.pth', help='model path')\n",
    "parser.add_argument('-m3',default='/home/ubuntu/workspace/kobaco/sketchy/U-2-Net/saved_models/seg_detection/u2net_human_seg.pth', help='model path')\n",
    "parser.add_argument('-f')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "model_dir_thin = args.m1\n",
    "model_dir_thick = args.m2\n",
    "model_dir_nobg = args.m3\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.set_device(2)\n",
    "# print(torch.cuda.current_device())   \n",
    "\n",
    "net = U2NET(3,1)\n",
    "\n",
    "torch_dict_thin = torch.load(model_dir_thin)\n",
    "torch_dict_thick = torch.load(model_dir_thick)\n",
    "torch_dict_nobg = torch.load(model_dir_nobg)\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     net.cuda()\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    \n",
    "print('-------------------------')\n",
    "\n",
    "def normPRED(d):\n",
    "    ma = torch.max(d)\n",
    "    mi = torch.min(d)\n",
    "\n",
    "    dn = (d-mi)/(ma-mi)\n",
    "\n",
    "    return dn\n",
    "\n",
    "def inference(net,input):\n",
    "\n",
    "    # normalize the input\n",
    "    tmpImg = np.zeros((input.shape[0],input.shape[1],3))\n",
    "    input = input/np.max(input)\n",
    "\n",
    "    tmpImg[:,:,0] = (input[:,:,2]-0.406)/0.225\n",
    "    tmpImg[:,:,1] = (input[:,:,1]-0.456)/0.224\n",
    "    tmpImg[:,:,2] = (input[:,:,0]-0.485)/0.229\n",
    "\n",
    "    # convert BGR to RGB\n",
    "    tmpImg = tmpImg.transpose((2, 0, 1))\n",
    "    tmpImg = tmpImg[np.newaxis,:,:,:]\n",
    "    tmpImg = torch.from_numpy(tmpImg)\n",
    "\n",
    "    # convert numpy array to torch tensor\n",
    "    tmpImg = tmpImg.type(torch.FloatTensor)\n",
    "    tmpImg = tmpImg.to(device)\n",
    "#     if torch.cuda.is_available():\n",
    "#         tmpImg = Variable(tmpImg.cuda())\n",
    "#     else:\n",
    "    tmpImg = Variable(tmpImg)\n",
    "\n",
    "    # inference\n",
    "    d1,d2,d3,d4,d5,d6,d7= net(tmpImg)\n",
    "\n",
    "    # normalization\n",
    "    pred = 1.0 - d1[:,0,:,:]\n",
    "    pred = normPRED(pred)\n",
    "\n",
    "    # convert torch tensor to numpy array\n",
    "    pred = pred.squeeze()\n",
    "    pred = pred.cpu().data.numpy()\n",
    "\n",
    "    del d1,d2,d3,d4,d5,d6,d7\n",
    "\n",
    "    return pred\n",
    "\n",
    "target_url = \"http://localhost:8912/predict\"\n",
    "\n",
    "def detect_single_face(img):\n",
    "#     img = cv2.imread('/home/ubuntu/workspace/kobaco/sketchy/U-2-Net/train_data/im2/804486H01_1_21-TJ-04-027_00534.jpg')\n",
    "    # img = cv2.resize(img, (640,480))\n",
    "    height,width = img.shape[0:2]\n",
    "    ori_img = img.copy()\n",
    "\n",
    "\n",
    "    _, img_encoded = cv2.imencode('.jpg', img, params=[cv2.IMWRITE_JPEG_QUALITY, 50])\n",
    "    img = cv2.imdecode(img_encoded, 1)\n",
    "    # send http request with image and receive response\n",
    "    jpg_as_text = base64.b64encode(img_encoded).decode()\n",
    "    dict = {}\n",
    "    dict['image'] = jpg_as_text\n",
    "    dict['shape'] = ori_img.shape\n",
    "\n",
    "    response = requests.post(target_url, data=json.dumps(dict))\n",
    "\n",
    "    # print('network inference 시간{0:0.2f}'.format(time.time()-strt ))\n",
    "    # draw_time = time.time()\n",
    "    lists = json.loads(response.text)\n",
    "\n",
    "    if len(lists) == 0:\n",
    "#         print(\"no face\")\n",
    "        return None\n",
    "    \n",
    "    conf = lists[0]['dots'][0]\n",
    "    coor = lists[0]['coor']\n",
    "    face_size = int(coor[3]-coor[1])\n",
    "    \n",
    "    resize_factor = int(0.7 * height / face_size)\n",
    "    if conf < 0.8:\n",
    "        return None\n",
    "#     print(resize_factor)\n",
    "    if resize_factor > 3:\n",
    "#         print('high')\n",
    "        im_face = cv2.resize(img, (1600, 900), interpolation = cv2.INTER_AREA)\n",
    "#         im_face = cv2.resize(img, (2560, 1440), interpolation = cv2.INTER_AREA)\n",
    "    elif resize_factor > 2:\n",
    "#         print('midium')\n",
    "        im_face = cv2.resize(img, (1280, 720), interpolation = cv2.INTER_AREA)\n",
    "#         im_face = cv2.resize(img, (1920, 1080), interpolation = cv2.INTER_AREA)\n",
    "    else:\n",
    "#         print('low')\n",
    "#         im_face = cv2.resize(img, (width*resize_factor,height*resize_factor), interpolation = cv2.INTER_AREA)\n",
    "#         im_face = cv2.resize(img, (960 ,540), interpolation = cv2.INTER_AREA)\n",
    "        im_face = cv2.resize(img, (1280, 720), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    return im_face\n",
    "\n",
    "def cartoonize(img):\n",
    "    target_url = \"http://localhost:8894/predict\"\n",
    "\n",
    "\n",
    "    _, img_encoded = cv2.imencode('.jpg', img, params=[cv2.IMWRITE_JPEG_QUALITY, 50])\n",
    "    img = cv2.imdecode(img_encoded, 1)\n",
    "    # send http request with image and receive response\n",
    "    jpg_as_text = base64.b64encode(img_encoded).decode()\n",
    "    dict = {}\n",
    "    dict['image'] = jpg_as_text\n",
    "\n",
    "    response = requests.post(target_url, data=json.dumps(dict))\n",
    "\n",
    "    lists = json.loads(response.text)\n",
    "    jpg_original = base64.b64decode(lists[0]['image'])\n",
    "    jpg_as_np = np.frombuffer(jpg_original, dtype=np.uint8)\n",
    "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
    "\n",
    "    return img\n",
    "\n",
    "@app.route('/sketch_thin', methods=['POST'])\n",
    "def sketch_thin():\n",
    "    global Model_Flag\n",
    "    \n",
    "    if request.method == 'POST':\n",
    "        \n",
    "        net.load_state_dict(torch_dict_thin)\n",
    "\n",
    "        r = request\n",
    "        data_json = r.data\n",
    "        data_dict = json.loads(data_json)\n",
    "\n",
    "        file_path = data_dict['path']\n",
    "#         print(file_path)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(\"input 경로에 이미지가 없습니다.\")\n",
    "            return jsonify([])\n",
    "        \n",
    "        im_list = []\n",
    "        if file_path.endswith('jpg') or file_path.endswith('png') or file_path.endswith('jpeg'):\n",
    "#             print(file_path)\n",
    "            im_list.append(file_path)\n",
    "        else:\n",
    "            print(\"이미지가 아닙니다.\")\n",
    "            return jsonify([])\n",
    "        \n",
    "        out_dir = args.o\n",
    "        if(not os.path.exists(out_dir)):\n",
    "            os.mkdir(out_dir)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "#             for i in range(0,len(im_list)):\n",
    "#             print(\"--------------------------\")\n",
    "#             print(\"inferencing \", 0, \"/\", len(im_list), im_list[0])\n",
    "\n",
    "            # load each image\n",
    "            img = cv2.imread(im_list[0])\n",
    "#                 height,width = img.shape[0:2]\n",
    "            im_face = detect_single_face(img)\n",
    "            if im_face is None:\n",
    "                return jsonify([])\n",
    "#             im_face = crop_face(img, face)\n",
    "\n",
    "            im_portrait = inference(net,im_face)\n",
    "#             im_portrait = inference(net,img)\n",
    "\n",
    "            dst = cv2.resize((im_portrait*255).astype(np.uint8), dsize = (1280, 720))\n",
    "#             dst = (im_portrait*255).astype(np.uint8)\n",
    "#             blr = cv2.GaussianBlur(dst, (0, 0), 2)\n",
    "#             dst2 = np.clip(2.0*dst - blr, 0, 255).astype(np.uint8)\n",
    "        \n",
    "            # save the output\n",
    "            out_path = out_dir+\"/\"+im_list[0].split('/')[-1][0:-4]+'.png'\n",
    "#             print(out_path)\n",
    "            if os.path.exists(out_path):\n",
    "                os.remove(out_path)\n",
    "            \n",
    "            cv2.imwrite(out_path, dst)\n",
    "            \n",
    "        result_dict = {}\n",
    "        result_dict['output_path'] = out_path\n",
    "        return jsonify(result_dict)\n",
    "\n",
    "@app.route('/sketch_thick', methods=['POST'])\n",
    "def sketch_thick():\n",
    "    if request.method == 'POST':\n",
    "        \n",
    "        net.load_state_dict(torch_dict_thick)\n",
    "        \n",
    "        r = request\n",
    "        data_json = r.data\n",
    "        data_dict = json.loads(data_json)\n",
    "\n",
    "        file_path = data_dict['path']\n",
    "        print(file_path)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(\"input 경로에 이미지가 없습니다.\")\n",
    "            return jsonify([])\n",
    "        \n",
    "        im_list = []\n",
    "        if file_path.endswith('jpg') or file_path.endswith('png') or file_path.endswith('jpeg'):\n",
    "#             print(file_path)\n",
    "            im_list.append(file_path)\n",
    "        else:\n",
    "            print(\"이미지가 아닙니다.\")\n",
    "            return jsonify([])\n",
    "        \n",
    "        out_dir = args.o\n",
    "        if(not os.path.exists(out_dir)):\n",
    "            os.mkdir(out_dir)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "#             for i in range(0,len(im_list)):\n",
    "#             print(\"--------------------------\")\n",
    "#             print(\"inferencing \", 0, \"/\", len(im_list), im_list[0])\n",
    "\n",
    "            # load each image\n",
    "            img = cv2.imread(im_list[0])\n",
    "#                 height,width = img.shape[0:2]\n",
    "#             img = cartoonize(img)\n",
    "\n",
    "#             im_face = detect_single_face(img)\n",
    "    \n",
    "#             if im_face is None:\n",
    "#                 return jsonify([])\n",
    "\n",
    "            im_portrait = inference(net,img)\n",
    "    \n",
    "#             im_portrait = inference(net,img)\n",
    "\n",
    "            dst = cv2.resize((im_portrait*255).astype(np.uint8), dsize = (1280, 720))\n",
    "#             dst = (im_portrait*255).astype(np.uint8)\n",
    "#             blr = cv2.GaussianBlur(dst, (0, 0), 2)\n",
    "#             dst2 = np.clip(2.0*dst - blr, 0, 255).astype(np.uint8)\n",
    "        \n",
    "            # save the output\n",
    "            out_path = out_dir+\"/\"+im_list[0].split('/')[-1][0:-4]+'.png'\n",
    "#             print(out_path)\n",
    "            if os.path.exists(out_path):\n",
    "                os.remove(out_path)\n",
    "            \n",
    "            cv2.imwrite(out_path, dst)\n",
    "            \n",
    "        result_dict = {}\n",
    "        result_dict['output_path'] = out_path\n",
    "        return jsonify(result_dict)\n",
    "    \n",
    "@app.route('/remove_bg', methods=['POST'])\n",
    "def remove_bg():\n",
    "    global Model_Flag\n",
    "    \n",
    "    if request.method == 'POST':\n",
    "        \n",
    "        net.load_state_dict(torch_dict_nobg)\n",
    "\n",
    "        r = request\n",
    "        data_json = r.data\n",
    "        data_dict = json.loads(data_json)\n",
    "\n",
    "        file_path = data_dict['img_path']\n",
    "#         print(file_path)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(\"input 경로에 이미지가 없습니다.\")\n",
    "            return jsonify([])\n",
    "        \n",
    "        im_list = []\n",
    "        if file_path.endswith('jpg') or file_path.endswith('png') or file_path.endswith('jpeg'):\n",
    "#             print(file_path)\n",
    "            im_list.append(file_path)\n",
    "        else:\n",
    "            print(\"이미지가 아닙니다.\")\n",
    "            return jsonify([])\n",
    "        \n",
    "        out_dir = args.o\n",
    "        if(not os.path.exists(out_dir)):\n",
    "            os.mkdir(out_dir)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "#             for i in range(0,len(im_list)):\n",
    "#             print(\"--------------------------\")\n",
    "#             print(\"inferencing \", 0, \"/\", len(im_list), im_list[0])\n",
    "#             print(im_list[0])\n",
    "            img = cv2.imread(im_list[0])\n",
    "            h, w = img.shape[:2]\n",
    "        \n",
    "            r = 360 / float(h)\n",
    "            dim = (int(w * r), 360)\n",
    "        \n",
    "            resized_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "            im_portrait = inference(net, resized_img)\n",
    "\n",
    "            dst = cv2.resize((im_portrait*255).astype(np.uint8), dsize = (w, h))\n",
    "\n",
    "#             print(dst.shape)\n",
    "#             mask2 = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "            ret, mask2 = cv2.threshold(dst, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#             kernel = np.ones((5,5), np.uint8)\n",
    "#             mask2 = cv2.morphologyEx(mask2, cv2.MORPH_CLOSE, kernel)\n",
    "#             mask2 = cv2.morphologyEx(mask2, cv2.MORPH_OPEN, kernel)\n",
    "            \n",
    "            mask2_inv = cv2.bitwise_not(mask2)\n",
    "\n",
    "            # dst_bg = cv2.bitwise_and(dst_img_copy, dst_img_copy, mask=mask_inv)\n",
    "#             print(mask2.shape)\n",
    "#             print(img.shape)\n",
    "            \n",
    "            dst = cv2.cvtColor(dst, cv2.COLOR_GRAY2BGR)\n",
    "            img_fg = cv2.bitwise_and(img, img, mask=mask2_inv)\n",
    "            img_bg = cv2.bitwise_and(dst, dst, mask=mask2)\n",
    "\n",
    "            dst = img_fg + img_bg\n",
    "            \n",
    "            # save the output\n",
    "#             out_path = out_dir+\"/\"+im_list[0].split('/')[-1][0:-4]+'.png'\n",
    "            out_path = os.path.join(out_dir,im_list[0].split('/')[-1][:-4]+'.png')\n",
    "#             print(out_path)\n",
    "            if os.path.exists(out_path):\n",
    "                os.remove(out_path)\n",
    "            \n",
    "            cv2.imwrite(out_path, dst)\n",
    "            \n",
    "        result_dict = {}\n",
    "        result_dict['output_path'] = out_path\n",
    "        return jsonify(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb508c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8895, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4bc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef103511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dalle-pytorch",
   "language": "python",
   "name": "dalle-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
