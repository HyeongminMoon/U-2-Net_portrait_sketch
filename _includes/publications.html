<head>
    <style>
      @import url(//fonts.googleapis.com/earlyaccess/jejumyeongjo.css);

      .jm-font{
          font-family: 'Jeju Myeongjo', serif;/*웹 폰트 지정*/
          color: black;
      }
      .b {
        background-color: #BBDEFB;
        padding: 10px 20px;
      }
    </style>
</head>

{% if page.title == "Home" %}

<h5 class="jm-font"> 머리말 </h5>
<p class="jm-font"> - 두번째 회사에서 입사하고 처음으로 맡게된 큰 프로젝트이다. 전체 프로젝트 내용은 영상을 4컷웹툰으로 바꾸는 것으로 전체 과정은 {키프레임 추출 및 이미지 캡셔닝-> 글자 제거-> 손실 영역 복원-> 
    스케치-> 얼굴변환} 이다. 이 글에서는 내가 주로 맡았고, 가장 많은 것을 익히게 되었던 스케치에 대한 부분을 이야기해보려고 한다. </p>
<p class="jm-font"> - 회사에서 진행한 일은 라이센스 상 문제가 될 수 있어서 코드레벨까지 공개하진 않는다. 따라 최대한 겪었던 문제와 어떻게 해결해는 지에 대해서 이야기한다. 나의 개발철학 상에서도
    코드는 하나의 도구일 뿐이지 중요한건 솔루션 과정에 발생한 문제해결을 위한 의사결정이다.</p>
<p class="jm-font"> - 이 글에서는 아무것도 없던 황무지에서 스케치모델을 개발해내면서 부딪혔던 수 많은 문제들과 해결방법들을 소개한다. 여담이지만, 터닝포인트가 될만한 솔루션이 나올때마다
    그때의 모델에 이름을 붙여서 예뻐하곤 했다. 열심히 공부하는 인공지능 아가의 아버지가 된 기분이랄까ㅋㅋ</p>
<br></br>

<h5 class="jm-font"> 요약</h5>
<p class="jm-font"> - 대충 발전 과정마다 사진과 핵심 키워드 화살표</p>
<br></br>


<h5 class="jm-font"> 개요</h5>
<p class="jm-font"> - 스케치 모델은 언뜻보면 생성모델로 보이므로 GAN을 사용할 것 같다. 그러나 GAN은 아직 불안정한 단계에 있고, 얼굴이 일그러지는 등의 모습을 흔치 않게 볼 수 있으며
     얼굴뿐만아니라 몸통, 옷, 배경 등을 포괄적으로 적용하기가 어렵다. 손이 얼굴로 인식되어 얼굴처럼 스케치되는 기이한 광경을 보고싶진 않다. 
     세그멘테이션을 극도로 발전시키면 CNN으로도 스케치모델을 만들 수 있다.</p>
<br></br>

<h5 class="jm-font"> 다양한 학습 데이터 수집(전처리) 방법 (이 문단 정리 필요)</h5>
<p class="jm-font"> - 주어진 문제에 따라 학습 데이터 수집 방법 또한 달라진다. 가장 좋은 경우는 당연히 지도학습할 문제 자체에 해당하는 학습 데이터가 존재하는 것이다. 또는 만드는 것이 간단하다면,
    예를들어 문제가 "헬멧을 쓴 사람과 쓰지 않은 사람을 구분하자" 이면 헬멧을 쓴 사람과 쓰지 않은 사람을 찍어서 헬멧을 쓴 부분을 바운딩 박스로 표시하면 된다.</p>
<p class="jm-font"> - 그러나 모든 문제가 이렇게 단순하다면 얼마나 좋을까. 때로는 수집할 수 없는 데이터 대상으로 학습해야하며, 때로는 지도할 수 없는(답이 정해지지않은) 데이터를 학습해야한다.
    이런경우에 활용할 수 있는 학습 데이터 수집방법들이 있다. 비전 중심으로 이야기하겠다.</p>
<p class="jm-font"> - 첫번째는 Numpy, Opencv를 활용해서 데이터 전처리 및 수정하는 것이다. 특히 Opencv에서는 다양한 기능을 제공하는데, Threshold를 통해 일정 밝기 이하의 픽셀을 제거하거나,
    Contour를 통해 mask를 딸 수도 있고 Contour Area를 활용해서 작은 노이즈를 지우거나 특정 색깔로 채울 수 있으며, bounding box를 구해서 자동으로 라벨링 하거나, minrect를 구해 물체의 기울기를 
    구할 수도 있고, 여러가지 Blur나 Morphology를 통해 물체의 테두리를 굵게/얇게 할 수도 있다.
    </p>
<p class="jm-font"> - 위에 나열한 방법은 내가 써보았던 방법 중 일부의 방법들이다. 읽으면서 떠오른게 있다면 적용해보자. 여기서 하고자하는 말은 정말 많은 기능들이 있으니 그 기능들을 활용해서 데이터
    를 만드려고 생각해보자는 것이다. 후술하겠지만 처음에는 모든 데이터를 건질 필요가 없다. 몇 개의 데이터라도 건져내기 시작하면 점점 가속이 붙는다. 이 부분은 이 문단을 모두 읽으면 이해갈 것이다.</p>
<p class="jm-font"> - 두번째는 다른 다양한 인공지능 모델을 이용하는 것이다. 이 프로젝트에서는 정말 다양한 인공지능 모델을 점차적으로 활용했는데, 그 중 한 가지 방법을 소개하자면 우리가 가진 사진들 
    중에서 얼굴이 크게 나온 사진들을 걸러내고, 이 사진들에 APDrawingGAN이라는 사람 사진에서 초상화를 그리는 모델을 적용시켜서 초상화 데이터셋을 늘려나갔다.</p>
<p class="jm-font"> - 세번째는 위 두가지 방법을 통해 얻은 적은 데이터로 학습을 한 뒤, 그나마 괜찮은 데이터들을 건져서, 다시 1,2번 방법을 적용하면서 점점 양질의 데이터들을 늘려나가는 것이다. 
    조금이라도 학습 데이터를 수집하기 시작하면 가속이 붙는다고 했던 이유이다. 처음엔 위 방법으로 초상화 데이터만 얻었지만, 이를 CNN 모델을 통해 학습한 뒤 배경이 들어있는 사진을 적용했다. 이외에도
    어그멘테이션을 활용하여 처음엔 큰 얼굴만 잘 그렸지만 작은 얼굴도 잘 그리게 한 뒤, 그 데이터를 학습하여 세밀한 옷표현이 된 데이터를 수집한다는 등으로 활용할 수 있다.
    그러면 개중 배경이 꽤 괜찮게 나온 사진들을 골라서 다시 Opencv를 활용해서 원하는 선의 굵기를 정하고, 노이즈들은 Contour Area 범위에 따라 제거할 수 있게 인터페이스를 만들어 작업했다.</p>
<p class="jm-font"> - 위 방법을 통해 1차적으로 학습한 모델은 다음과 같다. 아직 갈 길이 멀다고 느껴지지만 그래도 베이스 모델을 얻었다. 이제 모델이 발전하는 속도에는 점점 가속이 붙는다.</p>

<h5 class="jm-font"> 예시: 머리카락 채우기</h5>

<h5 class="jm-font"> 예시: 옷 주름 없애기</h5>

<h5 class="jm-font"> 어그멘테이션 </h5>


<h5 class="jm-font"> 배경과 사람을 따로해서 합성 </h5>
<p class="jm-font"> - 이질감 해소 방법</p>

<div style="text-align:left">
<br></br>
<h5 class="jm-font"> 결과 예시들 </h5>
<p class="jm-font"><br><img src="https://user-images.githubusercontent.com/32811724/147175829-eca9976a-840c-4c90-be47-417d95fb9dcc.jpg" width="20%" title="det1" alt="det1"></img>
<img src="https://user-images.githubusercontent.com/32811724/147175831-64ffea5f-4f69-4348-bbea-3eea60051e3f.jpg" width="20%" title="det2" alt="det2"></img>
<img src="https://user-images.githubusercontent.com/32811724/147175832-6a53944e-3605-420e-8e9b-3692a3a6fa86.jpg" width="20%" title="det3" alt="det3"></img><br/></p>
</div>

<br></br>

<h5 class="jm-font"> Triplet </h5>
<p class="jm-font"> - 다음으로는 포괄적인 이미지 자체의 특징 벡터를 추출하기 위한 모델을 설계했다. 모델은 efficientnet-b0을 이용했으며, 위에서 분류한 242분류를 기반으로 triplet 형식의 데이터 셋을
      만들어 학습하였다. Triplet이란 Input 이미지에 대해 유사한 이미지와 유사하지 않은 이미지, 총 3개로 이루어진 이미지 쌍을 말한다. Triplet loss를 이용하면 유사한 이미지와 그렇지
      않은 이미지 사이에 결과 벡터를 명확하게 구분되게끔 학습 할 수 있다.</p>
<br></br>

<h5 class="jm-font"> 코사인 유사도 </h5>
<p class="jm-font"> - 그렇게 학습된 모델에서 마지막 레이어의 완전결합층(Fully connected vector)의 벡터의 거리를 계산하여 이미지 유사도를 구하게 된다. 이때 벡터의 거리를 계산하는 방법은 유클리드 거리,
      L1 norm, L2 norm, 코사인 유사도 등 정말 다양하게 있다. 우리는 이미 분류표를 작성하는 단계에서 이를 고민하여 코사인 유사도를 사용하기로 했다. 
      분류표에서 비슷한 분류를 가깝게 위치하게 한다면 완전결합층에서도 비슷한 분류는 가까운 차원에 위치할 것이고, 이는 코사인 유사도 계산의 효과를 극대화 할 수 있기 때문이다.</p>
<p class="jm-font"> - 예를 들어 분류중에는 남자 아이와 여자 어른이 있다. 이 둘을 완전히 다른 분류라고 인식하면 문제가 있을 것이다. 따라서 이 두 분류를 가깝게 위치하면 코사인 벡터의 화살표가
      살짝 틀어져도 어느정도 유사성이 있다고 볼 수 있다.</p>
<br></br>

<h5 class="jm-font"> 이미지 유사도 </h5>
<p class="jm-font"> - 위의 두가지 모델에서 계산한 코사인 유사도를 곱해 최종 유사도를 계산한다. </p>
<p class="jm-font"> - 아래는 이 최종 유사도를 통해 검색한 유사도 순위 결과이다. 기존에 상용하는 유사 상표 검색 서비스들보다 월등하다.</p>

<br><img src="https://user-images.githubusercontent.com/32811724/147176073-92a8454d-9985-444d-b262-f7dfd4e51bd1.png" width="49%"></img>
<img src="https://user-images.githubusercontent.com/32811724/147176079-8fce7cc7-5017-4ead-9c3b-649fd01e1a67.png" width="49%"></img></br>
<br><img src="https://user-images.githubusercontent.com/32811724/147176080-073d99c5-0941-4394-bc08-d59c4fd16fd1.png" width="49%"></img>
<img src="https://user-images.githubusercontent.com/32811724/142619840-5c51e3bb-9ec6-44ee-a3bc-63b35ebf0211.png" width="49%"></img></br>

<br> </br>
<h5 class="jm-font"> 서비스 </h5>
<p class="jm-font"> 아래는 위의 모델들로 만들어진 간단한 웹 MVP이다. 백엔드는 Django, 프론트엔드는 React, 데이터 베이스는 MySQL, Redis를 사용하였다. </p>
<img src="https://user-images.githubusercontent.com/32811724/142619590-b5fa63a2-6b15-4720-9d99-cbd15fddc3c7.png" width="45%">
<img src="https://user-images.githubusercontent.com/32811724/142619604-3c5aeaad-fa1d-4b18-b169-804314554c2e.png" width="45%">

<br> </br>
<h5 class="jm-font"> 특허출원 </h5>
<p class="jm-font"> 관련해서 특허를 출원에 성공했다. </p>
<a style="color:blue" href = "https://doi.org/10.8080/1020200181271" style="color:blue">Patent METHOD OF SEARCHING TRADEMARKS AND APPARATUS FOR SEARCHING TRADEMARKS</a>

<script src="https://utteranc.es/client.js"
        repo="HyeongminMoon/FRCNN_trademark_similarity"
        issue-term="title"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>


<div class="row g-5 mb-5" style="text-align:left">
<hr width = "90%" color = "black">
<h5> Project Links </h5>
      {% for item in site.data.publications.featured %}
        <p><a href="{{ item.url }}">{{ item.name }}</a></p>
      {% endfor %}
    {% else %}
      includes publications.html
      {% for item in site.data.publications.index %}
        <p><a href="{{ item.url }}">{{ item.name }}</a></p>
      {% endfor %}
    {% endif %}
</div>
